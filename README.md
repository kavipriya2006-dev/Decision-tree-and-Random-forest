# Decision-tree-and-Random-forest
To create a Decision Tree and Random Forest, start by loading and preprocessing your dataset using pandas. Define your features (X) and target (y), ensuring proper data handling. Next, split the data into training and testing sets using train_test_split(), allocating 80% for training and 20% for evaluation. Train a Decision Tree Classifier by initializing DecisionTreeClassifier, setting parameters like max_depth to prevent overfitting, and fitting it to the training data. Visualize the tree structure using plot_tree() for better interpretability. Moving forward, train a Random Forest Classifier, which aggregates multiple decision trees for better accuracy and generalization. Compare its performance against the Decision Tree by predicting outcomes and calculating accuracy using accuracy_score(). Finally, analyze feature importance using rf.feature_importances_, ranking the predictors based on their influence. 
